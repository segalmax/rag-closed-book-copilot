{"question":"What does CAP stand for in distributed systems?","keywords":["consistency","availability","partition tolerance"],"reference_answer":"CAP stands for Consistency, Availability, and Partition Tolerance.","category":"direct_fact"}
{"question":"What is the default Kafka message retention period mentioned in the KB?","keywords":["retention","7 days","retention.ms"],"reference_answer":"The default Kafka retention policy is 7 days.","category":"direct_fact"}
{"question":"What key property does Kafka guarantee ordering for?","keywords":["partition","ordering","same key"],"reference_answer":"Kafka guarantees ordering within a partition; messages with the same key go to the same partition and preserve order there.","category":"direct_fact"}
{"question":"What does Redis Pub/Sub delivery guarantee according to the KB?","keywords":["at most once","pub/sub","not persisted"],"reference_answer":"Redis Pub/Sub is at-most-once delivery and does not persist messages for offline subscribers.","category":"direct_fact"}
{"question":"In a simple HTTP request lifecycle, what comes first: DNS resolution or TCP handshake?","keywords":["dns","tcp handshake","request lifecycle"],"reference_answer":"DNS resolution comes first, then the TCP handshake.","category":"temporal"}
{"question":"In cache-aside flow, what happens after a cache miss and before returning to the user?","keywords":["cache miss","fetch database","populate cache"],"reference_answer":"After a cache miss, the app fetches from the database, stores the result in cache, then returns it.","category":"temporal"}
{"question":"When should you prefer WebSockets over SSE?","keywords":["bidirectional","high frequency","websockets","sse"],"reference_answer":"Prefer WebSockets when you need frequent bidirectional communication; SSE is better for one-way server-to-client updates.","category":"comparative"}
{"question":"How is long polling different from simple polling?","keywords":["long polling","hold request open","simple polling","interval"],"reference_answer":"Simple polling sends requests at fixed intervals; long polling keeps a request open until data is available, then reconnects immediately.","category":"comparative"}
{"question":"Compare write-through and write-behind caching in terms of consistency and latency.","keywords":["write-through","write-behind","synchronous","asynchronous"],"reference_answer":"Write-through updates cache and DB synchronously for stronger freshness but higher latency; write-behind writes DB asynchronously for faster writes but higher risk.","category":"comparative"}
{"question":"How does consistent hashing compare to modulo hashing when nodes are added or removed?","keywords":["consistent hashing","modulo hashing","redistribution","node changes"],"reference_answer":"Modulo hashing remaps most keys when node count changes; consistent hashing remaps only a limited key range, reducing data movement.","category":"comparative"}
{"question":"What latency example is given for DB read vs Redis read in the caching article?","keywords":["50 milliseconds","1 millisecond","50x"],"reference_answer":"The KB gives an example of ~50 ms from Postgres vs ~1 ms from Redis, about a 50x improvement.","category":"numerical"}
{"question":"According to the Kafka deep dive, roughly how much can a single broker store and what peak throughput estimate is mentioned?","keywords":["1TB","1M messages per second","single broker"],"reference_answer":"The KB gives a rough estimate of about 1 TB stored and up to around 1M messages per second on good hardware.","category":"numerical"}
{"question":"What single-node PostgreSQL write-throughput ballpark is mentioned for simple inserts?","keywords":["5000 per second","simple inserts","per core"],"reference_answer":"The KB gives a rough ballpark of about 5,000 simple inserts per second per core for a well-tuned single node.","category":"numerical"}
{"question":"Why is choosing a Kafka partition key critical for scalability?","keywords":["partition key","hot partitions","load distribution"],"reference_answer":"Partition key choice determines distribution across partitions; poor keys create hot partitions and bottlenecks, while good keys spread load evenly.","category":"relationship"}
{"question":"Why do virtual nodes improve failure behavior in consistent hashing?","keywords":["virtual nodes","failure","load balance"],"reference_answer":"With virtual nodes, a failed node's keys are redistributed across many neighbors instead of one, preventing a single overloaded successor.","category":"relationship"}
{"question":"Why can adding indexes in PostgreSQL reduce write performance?","keywords":["index updates","wal","writes slower"],"reference_answer":"Each write must also update relevant indexes and WAL records, which adds extra work and reduces write throughput.","category":"relationship"}
{"question":"If you need realtime chat delivery and durable replay for disconnected users, which two KB ideas combine well?","keywords":["websockets","redis streams","durable","replay"],"reference_answer":"Use WebSockets for low-latency bidirectional delivery and pair them with a durable log like Redis Streams for replay/catch-up after reconnect.","category":"spanning"}
{"question":"How can PostgreSQL and Elasticsearch be used together based on the KB guidance?","keywords":["postgresql","full text","elasticsearch","advanced relevance"],"reference_answer":"Start with PostgreSQL full-text search for simpler needs; add Elasticsearch when you need advanced relevance, fuzzy matching, faceting, or larger distributed search.","category":"spanning"}
{"question":"For a read-heavy global product API with strict latency goals, what layered caching strategy does the KB imply?","keywords":["cdn","external cache","cache-aside","hot keys"],"reference_answer":"Use layered caching: CDN for static/public edge caching, external cache (Redis) with cache-aside for hot dynamic reads, and targeted mitigations for hot keys/stampedes.","category":"holistic"}
{"question":"For a collaborative editor requiring near-instant updates, what end-to-end approach is recommended across the realtime pattern discussion?","keywords":["websockets","pub/sub","connection management","state"],"reference_answer":"Use persistent client-server channels (typically WebSockets), route/propagate updates via pub/sub or hashing-based assignment, and handle reconnection/state consistency explicitly.","category":"holistic"}
{"question":"what kinds of cache are there?","keywords":["external caching","cdn","client-side caching","in-process caching"],"reference_answer":"The KB describes multiple cache layers: external caches (like Redis/Memcached), CDN caching at edge locations, client-side caching (browser/mobile/client libs), and in-process caching inside application servers.","category":"direct_fact"}
{"question":"when should i use websocket instead of sse?","keywords":["websocket","sse","bidirectional","high-frequency"],"reference_answer":"Use WebSockets when you need frequent bidirectional communication. Use SSE for one-way server-to-client streaming when clients rarely need to send realtime data back.","category":"comparative"}
{"question":"if redis is so fast why not use it for everything?","keywords":["durability tradeoff","in-memory","limitations","single node per request"],"reference_answer":"Redis is fast because it is in-memory, but it has tradeoffs: weaker durability guarantees than relational databases by default, and cluster limitations that require careful key design. It is great for caches and specific patterns, not a universal replacement.","category":"relationship"}
